{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "85750adc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85750adc",
        "outputId": "6d60964d-07b8-4227-a1fe-8a08652b71ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/wenruliu/adult-income-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 652k/652k [00:00<00:00, 1.05MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/wenruliu/adult-income-dataset/versions/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        " # Download latest version\n",
        "path = kagglehub.dataset_download(\"wenruliu/adult-income-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e3be8ecf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "e3be8ecf",
        "outputId": "ab8015f1-42a5-4557-f111-f265b4bab8ce"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/root/.cache/kagglehub/datasets/wenruliu/adult-income-dataset/versions/2\\\\adult.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1569553445.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mfr'{path}\\adult.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fnlwgt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'education'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'capital-gain'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'capital-loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hours-per-week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.cache/kagglehub/datasets/wenruliu/adult-income-dataset/versions/2\\\\adult.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(fr'{path}\\adult.csv')\n",
        "\n",
        "def prepocessing(df):\n",
        "\n",
        "    df.drop(columns=['fnlwgt', 'education', 'capital-gain', 'capital-loss', 'hours-per-week'], inplace = True)\n",
        "\n",
        "    fill_rows = ~(df == '?').any(axis = 1)\n",
        "    df = df[fill_rows]\n",
        "\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object' or pd.api.types.is_categorical_dtype(df[col]):\n",
        "          df[col], _ = pd.factorize(df[col])\n",
        "\n",
        "    return df\n",
        "\n",
        "def split_train_test(df, test_size=0.3):\n",
        "    # 1. Embaralha o DataFrame inteiro aleatoriamente\n",
        "    # Usa sample(frac=1) para selecionar 100% dos dados de forma aleatória\n",
        "    # random_state é usado para reprodutibilidade (sempre a mesma ordem se o número for o mesmo)\n",
        "    shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # 2. Calcula o ponto de corte\n",
        "    len_df = len(shuffled_df)\n",
        "    cut_point = len_df - round(len_df * test_size)\n",
        "\n",
        "    # 3. Divide o DataFrame embaralhado\n",
        "    train = shuffled_df[:cut_point]\n",
        "    test = shuffled_df[cut_point:]\n",
        "\n",
        "    print(f'Tamanho total: {len(df)}')\n",
        "    print(f'Tamanho do treino: {len(train)}')\n",
        "    print(f'Tamanho do teste: {len(test)}')\n",
        "\n",
        "    return train, test\n",
        "\n",
        "df = prepocessing(df)\n",
        "X_train, X_test = split_train_test(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feadc6a4",
      "metadata": {
        "id": "feadc6a4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class KNN_DP():\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Armazena os dados de treino\n",
        "        self.X_train = np.array(X)\n",
        "        self.y_train = np.array(y)\n",
        "\n",
        "    def euclidian_dist(self, row1, row2):\n",
        "        # Cálculo simples e robusto da distância euclidiana\n",
        "        # Raiz da soma das diferenças ao quadrado\n",
        "        diff = row1 - row2\n",
        "        return np.sqrt(np.sum(diff**2))\n",
        "\n",
        "    def get_vizinhos(self, test_row):\n",
        "        distancias = []\n",
        "        # Itera sobre todo o treino (pode ser lento, mas obedece \"sem bibliotecas de ML\")\n",
        "        for i in range(len(self.X_train)):\n",
        "            dist = self.euclidian_dist(test_row, self.X_train[i])\n",
        "            distancias.append((self.y_train[i], dist))\n",
        "\n",
        "        # Ordena pela distância (menor para maior)\n",
        "        distancias.sort(key=lambda x: x[1])\n",
        "\n",
        "        # Pega os k primeiros\n",
        "        vizinhos = distancias[:self.k]\n",
        "        return vizinhos\n",
        "\n",
        "    def predict_instance(self, test_row):\n",
        "        # KNN Tradicional\n",
        "        vizinhos = self.get_vizinhos(test_row)\n",
        "        classes_vizinhas = [v[0] for v in vizinhos]\n",
        "\n",
        "        # Votação majoritária simples\n",
        "        valores, contagens = np.unique(classes_vizinhas, return_counts=True)\n",
        "        indice_vencedor = np.argmax(contagens)\n",
        "        return valores[indice_vencedor]\n",
        "\n",
        "    def predict_instance_private(self, test_row, epsilon):\n",
        "        # KNN com Privacidade Diferencial (Mecanismo de Laplace na Votação)\n",
        "        vizinhos = self.get_vizinhos(test_row)\n",
        "        classes_vizinhas = [v[0] for v in vizinhos]\n",
        "\n",
        "        # Obtém as classes possíveis e suas contagens reais\n",
        "        valores_unicos = np.unique(self.y_train) # Todas as classes possíveis do problema\n",
        "\n",
        "        # Dicionário de contagem inicializado com 0\n",
        "        contagens = {val: 0 for val in valores_unicos}\n",
        "\n",
        "        # Contagem real dos vizinhos\n",
        "        for cls in classes_vizinhas:\n",
        "            contagens[cls] += 1\n",
        "\n",
        "        # Aplicação do Ruído de Laplace\n",
        "        # Sensibilidade (Delta f) para votação é 1 (mudar 1 vizinho muda o voto em 1)\n",
        "        # Scale (b) = Delta f / epsilon = 1 / epsilon\n",
        "        scale = 1.0 / epsilon\n",
        "\n",
        "        melhor_classe = None\n",
        "        maior_voto_ruidoso = -float('inf')\n",
        "\n",
        "        for cls in contagens:\n",
        "            # Gera ruído de Laplace\n",
        "            ruido = np.random.laplace(loc=0.0, scale=scale)\n",
        "            voto_ruidoso = contagens[cls] + ruido\n",
        "\n",
        "            if voto_ruidoso > maior_voto_ruidoso:\n",
        "                maior_voto_ruidoso = voto_ruidoso\n",
        "                melhor_classe = cls\n",
        "\n",
        "        return melhor_classe\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        # Predição padrão\n",
        "        X_test = np.array(X_test)\n",
        "        predicoes = []\n",
        "        for row in X_test:\n",
        "            pred = self.predict_instance(row)\n",
        "            predicoes.append(pred)\n",
        "        return np.array(predicoes)\n",
        "\n",
        "    def predict_private(self, X_test, epsilon):\n",
        "        # Predição com DP\n",
        "        X_test = np.array(X_test)\n",
        "        predicoes = []\n",
        "        for row in X_test:\n",
        "            pred = self.predict_instance_private(row, epsilon)\n",
        "            predicoes.append(pred)\n",
        "        return np.array(predicoes)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# EXECUTANDO O ALGORITMO (Simulação do fluxo pedido)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Supondo que você já tenha X_train, X_test, y_train, y_test separados\n",
        "# Ajuste as variáveis abaixo com seus dados reais\n",
        "# K = 10 conforme a instrução\n",
        "\n",
        "y_train= X_train['age'].values\n",
        "x_treino = X_train.drop(columns = ['age']).values\n",
        "y_test= X_train['age'].values\n",
        "x_teste = X_train.drop(columns = ['age']).values\n",
        "k = 10\n",
        "model = KNN_DP(k=k)\n",
        "\n",
        "# Treinamento\n",
        "print(\"Treinando modelo...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 1. Execução KNN Tradicional\n",
        "print(\"Executando KNN Tradicional...\")\n",
        "y_pred_padrao = model.predict(X_test)\n",
        "\n",
        "# Salvando resultado tradicional\n",
        "df_resultado = pd.DataFrame({\n",
        "    'y_true': y_test,\n",
        "    'y_pred': y_pred_padrao\n",
        "})\n",
        "df_resultado.to_csv('resultado_knn_tradicional.csv', index=False)\n",
        "print(\"Resultado Tradicional salvo.\")\n",
        "\n",
        "# 2. Execução KNN Privado para diferentes epsilons\n",
        "epsilons = [0.5, 1, 5, 10]\n",
        "\n",
        "for eps in epsilons:\n",
        "    print(f\"Executando KNN Privado (epsilon={eps})...\")\n",
        "    y_pred_privado = model.predict_private(X_test, epsilon=eps)\n",
        "\n",
        "    # Salvando resultado privado\n",
        "    nome_arquivo = f'resultado_knn_laplace_eps_{eps}.csv'\n",
        "    df_resultado_priv = pd.DataFrame({\n",
        "        'y_true': y_test,\n",
        "        'y_pred': y_pred_privado\n",
        "    })\n",
        "    df_resultado_priv.to_csv(nome_arquivo, index=False)\n",
        "    print(f\"Arquivo {nome_arquivo} salvo.\")\n",
        "\n",
        "print(\"Processo finalizado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "173357d1",
      "metadata": {
        "id": "173357d1"
      },
      "outputs": [],
      "source": [
        "def acuracia(pred, y_target):\n",
        "    return  sum(pred == y_target)/len(y_target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d2e228d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2e228d7",
        "outputId": "a272461d-6139-4b7e-c623-01ba5eb29be1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Gerando Dados Sintéticos ---\n",
            "Total de dados de treino: 100 linhas\n",
            "Dados de teste: [[2, 2], [8, 8], [5, 5], [10, 10], [0, 0]]\n",
            "------------------------------\n",
            "\n",
            ">>> Testando com Epsilon = 0.1\n",
            "(Muita Privacidade / Muito Ruído -> Esperamos erros)\n",
            "Ponto [2, 2] -> Classificado como: 0\n",
            "Ponto [8, 8] -> Classificado como: 1\n",
            "Ponto [5, 5] -> Classificado como: 0\n",
            "Ponto [10, 10] -> Classificado como: 1\n",
            "Ponto [0, 0] -> Classificado como: 0\n",
            "\n",
            ">>> Testando com Epsilon = 1.0\n",
            "Ponto [2, 2] -> Classificado como: 0\n",
            "Ponto [8, 8] -> Classificado como: 1\n",
            "Ponto [5, 5] -> Classificado como: 0\n",
            "Ponto [10, 10] -> Classificado como: 1\n",
            "Ponto [0, 0] -> Classificado como: 0\n",
            "\n",
            ">>> Testando com Epsilon = 10.0\n",
            "(Pouca Privacidade / Pouco Ruído -> Esperamos precisão)\n",
            "Ponto [2, 2] -> Classificado como: 0\n",
            "Ponto [8, 8] -> Classificado como: 1\n",
            "Ponto [5, 5] -> Classificado como: 0\n",
            "Ponto [10, 10] -> Classificado como: 1\n",
            "Ponto [0, 0] -> Classificado como: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "class MecanismoLaplace:\n",
        "\n",
        "    def __init__(self, epsilon):\n",
        "        # Guarda o orçamento total de privacidade definido pelo usuário.\n",
        "        self.epsilon = epsilon\n",
        "    \"Função que pega um valor real (contagem de vizinhos) e adiciona um valor aleatório (ruído).\"\n",
        "    def adicionar_ruido(self, valor_real, sensibilidade, num_classes):\n",
        "\n",
        "        # Divisão do orçamento\n",
        "        epsilon_fracionado = self.epsilon / num_classes\n",
        "        #Calculo da escala\n",
        "        escala = sensibilidade / epsilon_fracionado\n",
        "\n",
        "        #Gera um ruido aleatorio, com média do ruído zero e definindo a dispersão do ruído como a escala\n",
        "        ruido = np.random.laplace(loc=0.0, scale=escala)\n",
        "\n",
        "        # Retorna a soma do valor original com o ruído gerado.\n",
        "        return valor_real + ruido\n",
        "\n",
        "#Implementa o algoritmo de vizinhos no raio\n",
        "class ClassificadorRaioPrivado:\n",
        "\n",
        "    def __init__(self, raio=6.0):\n",
        "        # Define a distância máxima para considerar um ponto como vizinho.\n",
        "        self.raio = raio\n",
        "\n",
        "        # Variáveis para guardar os dados de treino.\n",
        "        self.X_treino = None\n",
        "        self.y_treino = None\n",
        "        self.classes_unicas = None\n",
        "\n",
        "    def treinar(self, X, y):\n",
        "        # Converte a lista de características de x e y para um array NumPy.\n",
        "        self.X_treino = np.array(X)\n",
        "        self.y_treino = np.array(y)\n",
        "\n",
        "        #Pega apenas a lista de classes distintas\n",
        "        self.classes_unicas = np.unique(self.y_treino)\n",
        "\n",
        "    def distancia_euclidiana(self, linha1, linha2):\n",
        "\n",
        "        #Calcular a distancia entre duas coordenadas\n",
        "        diferenca = linha1 - linha2\n",
        "\n",
        "        #Calcula da distancia usando Pitágoras\n",
        "        distancia = np.sqrt(np.sum(diferenca**2))\n",
        "\n",
        "        # Retorna a distância.\n",
        "        return distancia\n",
        "\n",
        "    #Busca os vizinhos proximos\n",
        "    def obter_vizinhos_no_raio(self, linha_teste):\n",
        "\n",
        "        # Lista para guardar as classes dos vizinhos encontrados.\n",
        "        vizinhos_encontrados = []\n",
        "\n",
        "        # Loop que passa por cada linha da base de treinamento.\n",
        "        for i in range(len(self.X_treino)):\n",
        "\n",
        "            # Calcula a distância entre o ponto de teste atual e o ponto de treino i.\n",
        "            dist = self.distancia_euclidiana(linha_teste, self.X_treino[i])\n",
        "\n",
        "            # Verifica se a distância é menor ou igual ao raio 6.\n",
        "            if dist <= self.raio:\n",
        "                # Se estiver dentro do raio, adicionamos a classe desse vizinho na lista.\n",
        "                vizinhos_encontrados.append(self.y_treino[i])\n",
        "\n",
        "        # Retorna a lista com as classes de todos os vizinhos próximos.\n",
        "        return vizinhos_encontrados\n",
        "\n",
        "    #Faz a classificação\n",
        "    def prever_instancia_privada(self, linha_teste, epsilon):\n",
        "\n",
        "        # Chama a função interna para pegar as classes de quem está perto.\n",
        "        lista_classes_vizinhas = self.obter_vizinhos_no_raio(linha_teste)\n",
        "\n",
        "        # Cria um dicionário com todas as classes possíveis iniciando com 0 votos.\n",
        "        contagens_reais = {classe: 0 for classe in self.classes_unicas}\n",
        "\n",
        "        # Conta quantos vizinhos existem para cada classe.\n",
        "        for classe_vizinha in lista_classes_vizinhas:\n",
        "            # Incrementa o contador daquela classe.\n",
        "            contagens_reais[classe_vizinha] += 1\n",
        "\n",
        "        # Instancia a nossa classe de ruído com o epsilon fornecido.\n",
        "        mecanismo = MecanismoLaplace(epsilon)\n",
        "\n",
        "        # Verifica quantas classes existem no total para dividir o epsilon.\n",
        "        total_classes = len(self.classes_unicas)\n",
        "\n",
        "        # Dicionário para guardar os votos com ruído.\n",
        "        contagens_ruidosas = {}\n",
        "\n",
        "        # Loop para aplicar ruído em TODAS as classes possíveis, mesmo se a classe teve voto 0\n",
        "        for classe in self.classes_unicas:\n",
        "            # Pega a contagem verdadeira.\n",
        "            valor_verdadeiro = contagens_reais[classe]\n",
        "\n",
        "            # Chama a função que adiciona o ruído de Laplace, definindo a sensibilidade como 1.\n",
        "            valor_com_ruido = mecanismo.adicionar_ruido(\n",
        "                valor_real=valor_verdadeiro,\n",
        "                sensibilidade=1.0,\n",
        "                num_classes=total_classes\n",
        "            )\n",
        "\n",
        "            # Guarda o valor ruidoso no dicionário.\n",
        "            contagens_ruidosas[classe] = valor_com_ruido\n",
        "\n",
        "        #Definir a melhor classe nos valores com ruído\n",
        "        melhor_classe = None\n",
        "        maior_valor_encontrado = -float('inf') # Inicializar com o menor valor possivel.\n",
        "\n",
        "        # Varre o dicionário de contagens ruidosas para achar o maior valor.\n",
        "        for classe, valor in contagens_ruidosas.items():\n",
        "            # Se o valor atual for maior que o recorde anterior.\n",
        "            if valor > maior_valor_encontrado:\n",
        "                # Atualiza o recorde.\n",
        "                maior_valor_encontrado = valor\n",
        "                # Define essa classe como a vencedora.\n",
        "                melhor_classe = classe\n",
        "\n",
        "        # Retorna a classe que teve a maior contagem ruidosa.\n",
        "        return melhor_classe\n",
        "    #Recebe  os dados de teste e aplica a predição com base nos valores ruidosos\n",
        "    def prever_privado(self, X_teste, epsilon):\n",
        "\n",
        "        # Garante que X_teste seja um array numpy.\n",
        "        X_teste = np.array(X_teste)\n",
        "\n",
        "        # Lista para guardar todas as previsões.\n",
        "        lista_predicoes = []\n",
        "\n",
        "        # Loop que passa linha por linha da base de teste.\n",
        "        for linha in X_teste:\n",
        "            # Chama a função, que retorna a predição com base nos valores com ruído.\n",
        "            predicao = self.prever_instancia_privada(linha, epsilon)\n",
        "\n",
        "            # Adiciona o resultado na lista de predições.\n",
        "            lista_predicoes.append(predicao)\n",
        "\n",
        "        # Transforma a lista final em um array numpy e retorna.\n",
        "        return np.array(lista_predicoes)\n",
        "\n",
        "\n",
        "\n",
        "########Simulação###############\n",
        "# ... (Mantenha as classes MecanismoLaplace e ClassificadorRaioPrivado aqui em cima) ...\n",
        "\n",
        "######## Simulação com Mais Dados ###############\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Define uma \"semente\" para os números aleatórios.\n",
        "    # Isso garante que sempre que você rodar, os dados gerados serão os mesmos.\n",
        "    np.random.seed(42)\n",
        "\n",
        "    print(\"--- Gerando Dados Sintéticos ---\")\n",
        "\n",
        "    # 1. Gerando a Classe 0 (50 pontos ao redor de 2,2)\n",
        "    # np.random.randn cria números numa curva normal. Somamos +2 para mover o centro.\n",
        "    X_classe0 = np.random.randn(50, 2) + 2\n",
        "    y_classe0 = [0] * 50 # Lista com 50 zeros\n",
        "\n",
        "    # 2. Gerando a Classe 1 (50 pontos ao redor de 8,8)\n",
        "    # Somamos +8 para mover o centro para longe da classe 0.\n",
        "    X_classe1 = np.random.randn(50, 2) + 8\n",
        "    y_classe1 = [1] * 50 # Lista com 50 uns\n",
        "\n",
        "    # 3. Juntando tudo no conjunto de Treino\n",
        "    # np.concatenate cola os arrays um embaixo do outro.\n",
        "    X_treino = np.concatenate([X_classe0, X_classe1])\n",
        "    y_treino = np.concatenate([y_classe0, y_classe1])\n",
        "\n",
        "    print(f\"Total de dados de treino: {len(X_treino)} linhas\")\n",
        "\n",
        "    # 4. Criando pontos de Teste Estratégicos\n",
        "    dados_teste = [\n",
        "        [2, 2],   # Ponto bem no meio da Classe 0 (Deveria ser 0)\n",
        "        [8, 8],   # Ponto bem no meio da Classe 1 (Deveria ser 1)\n",
        "        [5, 5],   # Ponto no \"limbo\" entre os dois (Dúvida cruel)\n",
        "        [10, 10], # Ponto extremo da Classe 1 (Deveria ser 1)\n",
        "        [0, 0]    # Ponto extremo da Classe 0 (Deveria ser 0)\n",
        "    ]\n",
        "\n",
        "    print(f\"Dados de teste: {dados_teste}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # 5. Instancia e Treina o Modelo\n",
        "    # Raio 6.0 é grande o suficiente para pegar bastante gente nesse cenário\n",
        "    modelo = ClassificadorRaioPrivado(raio=6.0)\n",
        "    modelo.treinar(X_treino, y_treino)\n",
        "\n",
        "    # 6. Testando com diferentes Epsilons (Orçamentos de Privacidade)\n",
        "    lista_epsilons = [0.1, 1.0, 10.0]\n",
        "\n",
        "    for eps in lista_epsilons:\n",
        "        print(f\"\\n>>> Testando com Epsilon = {eps}\")\n",
        "\n",
        "        if eps == 0.1:\n",
        "            print(\"(Muita Privacidade / Muito Ruído -> Esperamos erros)\")\n",
        "        elif eps == 10.0:\n",
        "            print(\"(Pouca Privacidade / Pouco Ruído -> Esperamos precisão)\")\n",
        "\n",
        "        # Faz a predição\n",
        "        predicoes = modelo.prever_privado(dados_teste, epsilon=eps)\n",
        "\n",
        "        # Mostra o resultado lado a lado\n",
        "        for i, ponto in enumerate(dados_teste):\n",
        "            print(f\"Ponto {ponto} -> Classificado como: {predicoes[i]}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Privacidade_Diferencial",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}